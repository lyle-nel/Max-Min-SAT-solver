# Max-Min-SAT-solver
Solving Min and Max SAT problems through population based metaheuristics.

This project includes some of my initial research and ideas around stochastic optimisation of SAT, unweighed MAX-SAT and unweighed MIN-SAT problems using population based metaheuristics. This project will very likely include duplicate work and rediscoveries since I was curious how far I could get without consulting the existing literature on SAT optimisation. It vexes me a bit that the work is incomplete but I have run out of personal time to continue work on this for the time being.

## Performance characteristics:
One generally observes extremely rapid convergence to >99% clauses satisfied. The algorithm spends most of its time improving on the initial >99% convergence. Although convergence is faster for smaller instances, it performs nearly equally as well for larger instances.

## How the algorithm and many of its variants work:
### Base Algorithm:
A steady state genetic algorithm with crossover and mutation on a standard bitstring genome. Both crossover and mutation operators have no domain knowledge of what the underlying genome represents. Crossover selects two random organisms from the pool and performs a partial replacement of one genome onto the other with a random mask. The random mask's density of 1s and 0s is controlled by a density coefficient. The mutation operator performs a point mutation and a flip mutation. The intensity of both point and flip mutations are controlled by its respective coefficients.

The simplest variant of fittness is simply counting the number of clauses satisfied. Due to the steady state approach, selection is somewhat different since it is continuous. Here, the simplest implementation of selection is to select a random victim in the pool of organisms and compare the fitness of the new organism with the victim, if the vitim is less fit it gets replaced. Growing the pool instead of replacing organisms seems to significantly reduce convergence. Also take note how the selection process does not simply allow the 'best' organism to enter the pool, instead it allows for anything but the worst. This helps avoid premature convergence on local optima as well as provide a larger set of solutions from which to derive new solutions.

### Selection variants:
To further improve exploration and avoid getting stuck in local optima, the simulation must allow for sub-optimal intermediate organisms to survive for a sufficient period of time for its genes to drift out of the local optima. This is achieved by making selection somewhat noisy, that is, in addition to an organism replacing its victim based on fittness, an organism can be replaced by chance as well, irregardless of fittness. No extensive experimentation has been done to determine good values for this noise parameter.

To improve the long-term memory of the simulation so that 'good' partial solutions do not get lost, we can introduce a 'best organisms' list. When using this list, modification of the crossover function is required to crossover organisms in this list and reintroduce them into the pool. The way that organisms find themselves into the the 'best organisms' list is somewhat different to the selection process in the pool. The 'best organisms' list is also bounded but it starts of nearly empty. To populate the list, at each increment of the simulation, the least fit organism from the 'best organism' list is selected and is compared with the candidate organism. The candidate organism is placed alongside the other 'best' organisms if it is more fit than the least fit organism untill such time that the bound of the list is reach. When this happens, the worst performing organism is replaced instead.
There are a few other subtle advantages to this variant. For example, if the simulation gets stuck in local optima, sufficiently good offspring organisms are available to force the simulation out of the local optima, partially resetting the simulation to an earlier state. There are a few disadvantages to this approach when used alongside some of the other variants, which will be discussed below.

### Smuggling hyperparameters into the simulation:
The parameters we will be looking at here are the random mask density, point mutation rate, flip mutation rate and crossover rate. Until now, all the above mentioned parameters remain static over the lifetime of the simulation. However, we don't know what 'good' values to assign to these parameters. That being said, we can smuggle some of these parameters into the organism as just another part of its genome and let the simulation select what values work best for the organisms. Some adjustments need to be made to the mutation and crossover operators to incorporate these parameters as part of the simulation. In the mutation operator, alongside the flip and point mutations, we make small random changes to the new parameters of the current organism being mutated. In the crossover operator we set the offspring organisms flip mutation rate to the left parent and the point mutation to the right parent. Information from both parents allow faster convergence on 'good' values. The crossover density and crossover rate is taken from one parent only since an interleaved approach seems to destructive to be effective.

Note that the 'best organisms' variant is mostly incompatible with parameter optimisation. Parameter values need sufficient opportunity to drift, however, a 'best organism' list will impede this since the paramter values will get pulled back every time an offspring enters the pool from the 'best organisms' list.

Because each organism optimises for its own good parameter values, organisms that have a higher tolerance for the destructive effect of crossovers can incorporate information faster from its parents, whereas organisms that perform better on asexual reproduction can reduce the rate of crossover and density of the crossover mask while increasing point and or flip mutations to maximise its fitness. The parameters controlling the rate of crossover and mutation also has an annealing effect since organisms favour smaller changes as the simulation progresses due to there being fewer opportunities for improvement when making large changes.

### Fitness variants:
The initial naive approach of simply using the number of clauses satisfied as the fitness has a few problems. Firstly, due to the discrete nature of the number of clauses satisfied, the fitness landscape is less smooth, which implies that organisms are more likely to get stuck. Secondly, one should not assume that all clauses are equal in how difficult they are to satisfy. To address these issues we introduce a simple counter for each clause. The counter value for each clause is set to some constant, then for every time that a clause is unsatisfied when measuring the fitness, we increase the counter. To find the fitness we do not sum the number of clauses satisfied, instead we sum the counter value of each clause that is satisfied. This way, clauses that are inherently hard to satisfy become more attractive over time since satisfying it increases the fitness of the organism significantly. This approach also has the effect of providing stochastic backtracking since it may be the case that satisfying a hard clause is worth it even if it means that other easy clauses become unsatisfied. Behaviour emerges where organisms backtrack to satisfy a hard clause and then start working on satifying the easier ones again. Lastly, it has a smoothing effect on the fitness landscape due to the fitness landscape being dynamic. This smoothing effect is worth investigating on its own at some later stage.

Although the counter based variant improves the performance of the algorithm overall, it tends to perform worse over time as the simulation continues. The reason for this drop in its effectiveness is that certain clauses may take such a long time to satisfy, so by the time it is satisfied, its counter value is so large that it completely dominates any of the other clauses. However, this dominating clause might actually be easy to satisfy eventually, but any clauses that become hard to solve after that will have difficulty exceeding the counter value of the clause that was previously hard to satisfy. To account for this, we initialise each counter with a sufficiently large value, then whenever a counter for an unsatisfied clause is incremented, a random clause's counter is decremented. This has the effect of allowing previously large counters to decay over time and makes the counters reflect more accurately what clauses are currently difficult to satisfy.

### Observations on the maximum and minimum clauses solved for a specific truth assignment density:
When finding random max and min solutions in the form of a bitstring, where the bitstring has a fixed number of possible truth assignments, which we call the density, one notices that each SAT problem has a unique profile. This profile shows that number of clauses satisfied given a particular density is similar to its ajacent densities, which approximates a smooth curve over the range of densities. This adjacent similarity comes as a surprise since it implies that simply by virtue of analysing the profile, we know where worse solutions lie and where better solutions lie. For example some sat problems would have a signmoid profile indicating that good solutions and perhaps the complete solution can be found when the truth assignment density is higher than 0.5. Others will have a curve with distinct local and global optima, which hints to regions where the simulation might find itself in a local optima. This observation allows us to do a number of things. Firstly, we can avoid local optima where apparent. Secondly, we can control the truth assignment density to densities that would be most promising as indicated by the profile. Thirdly, we can initialise the pool with 'good' organisms that have been found through randomly generated solutions in a uniform way. The pool would be armed with organisms that have a truth assignment density of promising regions. Since organisms tend to prefer flip mutations over point mutations, these densities are generally well preserved for as long as it remains fit. This initial sampling can lead to very rapid maximisation of sat clauses once the GA kicks in.

### Marking fruitless regions to reduce exploration in those areas:
The naive approach would be to keep a list of organisms already considered during the simulation, however, this is not very effective since the set of previously considered solutions grow quickly and it is less likely to be general enough to be effective.
Alternatively, If we assume that SAT problems generally have a smooth profile as discussed above, we can explore promising densities for some time and if no progress is made, we can safely say that that specific truth assignment density is less likely to contain good solutions. For its implementation we can use a simple array populated with floating point values. The size of the array is proportional to our desired granularity we wish to have for representing regions. For example, an array with two elements would represent solutions with density [0.0-0.5) and (0.5-1.1] respectively. Each floating point value is chosen proportional to the number of bitstring permutations for that given density. When calculating the fitness, we multiply the final score with the floating point value for the organisms bitstring density. Over time we decrease the floating point value for the current density being evaluated. This has the effect of making solutions of a particular density seem less fit if it is used very often.

ebc2a720957cf10090c78454e629c1a5346461ef6a9e36dd3c0bd9618f3bbf1fb9e2736829bff7b4278593d64640127ee45e720703459ed9c959a88167556aa8
cdbfeea5d6c7c15c60c290c2798bec70804a0ba4a1e084d805de1a66348d4d9186f21a2d3e6a33627a324fa58c0ad8243234d739607d1fad2a4c25bede325bff
4b57978078aaee6807acc4e646fab168cf09c3df761ee92dbcadd5145e2abf65b3c70f54d191525d479291485aef03883da0e9be809d288a1edb4c72c771242d
62707f4e6d6e278a35c1a80dbe40e0779bcb1ba46e4963191e9628d992d3ccc7c4695a13a44215aad0181eae49984f4476bad3b143fcaadfd86fdd262b895ca1
41fbe3cd40a9ca0cb8a8c097065ac5e29f8774328916cde4ee8af75129edc9b7d2228e82f8310eb7418383f558e28f336f94fc9446bf04c7ed0b9ffb966847a1
